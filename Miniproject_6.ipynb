{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Image Feature Extraction (Hard)\n",
        "-Extract features from the CIFAR-10 image dataset using the appropriate\n",
        "method\n"
      ],
      "metadata": {
        "id": "2e6lZpwQt5X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "t_N6c19BgazM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "Ub9CO81qf1GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e103544-e70e-4e35-9cf3-97352a2fd7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "hh_hof79gkpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
      ],
      "metadata": {
        "id": "MjS9RUmNgooi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f8e8e2-14b6-41f0-be51-b40f22a83aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = base_model.layers[-1].output\n",
        "output = GlobalAveragePooling2D()(output)"
      ],
      "metadata": {
        "id": "aQmD-__6gz_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "isUbOmGEgzxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Train a simple classifier on the extracted features for image\n",
        "classification."
      ],
      "metadata": {
        "id": "_YkY_cc1uE3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n"
      ],
      "metadata": {
        "id": "G04J8aeXkzpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = np.random.rand(60000, 784)\n",
        "y_train = np.random.randint(0, 10, size=(60000))\n",
        "y_train_categorical = to_categorical(y_train)\n",
        "\n",
        "x_test_features = np.random.rand(10000, 784)\n",
        "y_test = np.random.randint(0, 10, size=(10000))\n",
        "y_test_categorical = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "L95xhaQNk5fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=128, activation='relu', input_dim=784))\n",
        "classifier.add(Dense(units=10, activation='softmax'))\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8YzI84Klk7mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(x_train_features, y_train_categorical, epochs=10, batch_size=128, validation_data=(x_test_features, y_test_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IiOsLZqk-3b",
        "outputId": "5fee5dc4-68f2-4e9b-8eed-911ce9ff25f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 2.3086 - accuracy: 0.0990 - val_loss: 2.3025 - val_accuracy: 0.1017\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3024 - val_accuracy: 0.1041\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3025 - val_accuracy: 0.1037\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3024 - val_accuracy: 0.1056\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3025 - val_accuracy: 0.0985\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3024 - val_accuracy: 0.1042\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3024 - val_accuracy: 0.0985\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3025 - val_accuracy: 0.0985\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3024 - val_accuracy: 0.1042\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3025 - val_accuracy: 0.0975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x787da607de40>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QW8s6LyylCNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}